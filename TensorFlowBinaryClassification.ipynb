{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlowBinaryClassification.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyNbDvdQOarotfnIAcONlXZa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagyant/sample_codes/blob/main/TensorFlowBinaryClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQa3vVJVx5vb"
      },
      "source": [
        "!pip3 install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89MXBGxj0XBZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from random import randint\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsC6UHftsiPy"
      },
      "source": [
        "train_label = []\n",
        "train_sample = []\n",
        "for i in range(50):\n",
        "  # 5% below 65 having side effects\n",
        "  new_age = randint(13,64)\n",
        "  train_sample.append(new_age)\n",
        "  train_label.append(1)\n",
        "\n",
        "  # 5% above 64 not having side effects\n",
        "  new_age = randint(65, 100)\n",
        "  train_sample.append(new_age)\n",
        "  train_label.append(0)\n",
        "\n",
        "for i in range(1000):\n",
        "  # 95% below 65 not having side effects\n",
        "  new_age = randint(13,64)\n",
        "  train_sample.append(new_age)\n",
        "  train_label.append(0)\n",
        "\n",
        "  # 95% above 64 having side effects\n",
        "  new_age = randint(65, 100)\n",
        "  train_sample.append(new_age)\n",
        "  train_label.append(1)\n",
        "\n",
        "# Formatting data and getting ready in format acceptable by model\n",
        "# Also suffling teh data for better training\n",
        "train_sample = np.array(train_sample)\n",
        "train_label = np.array(train_label)\n",
        "train_sample, train_label = shuffle(train_sample, train_label)\n",
        "\n",
        "# Scaling the data in the range (0,1) using MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_train_sample = scaler.fit_transform(train_sample.reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hFaxomSC5rZ"
      },
      "source": [
        "train_model, test_model, train_model_label, test_model_label = train_test_split(scaled_train_sample, train_label, train_size = 0.9, random_state = 36)\n",
        "# print(test_model.shape , '-', test_model_label.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHwJyPNh8C4R"
      },
      "source": [
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(\"Number of GPUs Available: \", len(physical_devices))\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc8Zr5Sn5Tdc"
      },
      "source": [
        "# Dense is the Dense layer that is most widely used neural network layer which \n",
        "# is also known as fully connected layer. The first Dense layer is the first\n",
        "# hidden layer while we do not haveto explicitly declare input layer.\n",
        "model = Sequential(\n",
        "    [Dense(units=32, activation='relu', input_shape=(1,)),\n",
        "     Dense(units=16, activation='relu'),\n",
        "     Dense(units=2, activation='softmax')]\n",
        ")\n",
        "\n",
        "# summary() of model instance can be used tovisually see wht has been created\n",
        "# and how many parameters used\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZx80skB_SqB"
      },
      "source": [
        "# compile methods gets the model ready for training by passing all the necessary\n",
        "# parameters and metrics\n",
        "model.compile(optimizer=Adam(learning_rate=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD5LgnGEAxEB"
      },
      "source": [
        "# fit method actually does the training and gets model ready for validation\n",
        "# batch_size is the total number of data points handled in each batch run\n",
        "# so if batch size is 10 and total data points are 50 then number of batches\n",
        "# will be 50/10 = 5 per epoch. This is something related to efficiency\n",
        "# epochs : total number of iterations of complete data set done for training.\n",
        "# shuffle is by default True so i am removing it from the fit function.\n",
        "model.fit(\n",
        "    x=train_model, y=train_model_label, batch_size=20, epochs=50, verbose=2\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM_b84F8BrKW"
      },
      "source": [
        "# There are 2 ways, 1 : validation_data 2 : validation_split \n",
        "# Demonstrating the 1st way where the data should be a tuple (x_val, y_val)\n",
        "# And second way where we use a split\n",
        "model.fit(\n",
        "     x=train_model\n",
        "    ,y=train_model_label\n",
        "    ,validation_data=valid_set\n",
        "    ,epochs=50\n",
        "    ,batch_size=20\n",
        "    ,verbose=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd1TRdOWjU2b"
      },
      "source": [
        "# valid_set for input of first method\n",
        "valid_set = np.array(zip(list(test_model), list(test_model_label.reshape(-1,1))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTF8OCXAkjFP"
      },
      "source": [
        "test_model_label = test_model_label.reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy5RnLjFWptA"
      },
      "source": [
        "test_model.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0mXVwiQXKyC"
      },
      "source": [
        "valid_set = np.concatenate((test_model, test_model_label), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r05bNN7TaeiA"
      },
      "source": [
        "test_label = []\n",
        "test_sample = []\n",
        "for i in range(10):\n",
        "  # 5% below 65 having side effects\n",
        "  new_age = randint(13,64)\n",
        "  test_sample.append(new_age)\n",
        "  test_label.append(1)\n",
        "\n",
        "  # 5% above 64 not having side effects\n",
        "  new_age = randint(65, 100)\n",
        "  test_sample.append(new_age)\n",
        "  test_label.append(0)\n",
        "\n",
        "for i in range(200):\n",
        "  # 95% below 65 not having side effects\n",
        "  new_age = randint(13,64)\n",
        "  test_sample.append(new_age)\n",
        "  test_label.append(0)\n",
        "\n",
        "  # 95% above 64 having side effects\n",
        "  new_age = randint(65, 100)\n",
        "  test_sample.append(new_age)\n",
        "  test_label.append(1)\n",
        "\n",
        "# Formatting data and getting ready in format acceptable by model\n",
        "# Also suffling the data for better training\n",
        "test_sample = np.array(test_sample)\n",
        "test_label = np.array(test_label)\n",
        "test_sample, test_label = shuffle(test_sample, test_label)\n",
        "\n",
        "# Scaling the data in the range (0,1) using MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_test_sample = scaler.fit_transform(test_sample.reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mPBiigDeXDy"
      },
      "source": [
        "scaled_test_sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcPORE42cTLl"
      },
      "source": [
        "predicted = model.predict(scaled_test_sample, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zZcpB1Iitc1"
      },
      "source": [
        "pred_label = []\n",
        "for i,j in predicted:\n",
        "  if i > j:\n",
        "    pred_label.append(0)\n",
        "  else:\n",
        "    pred_label.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vMaHfookFgQ"
      },
      "source": [
        "confusion_matrix(pred_label, test_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwVVyYXck_Aj"
      },
      "source": [
        "accuracy_score(test_label, pred_label)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}